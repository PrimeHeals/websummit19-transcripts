
Casey Lau: 100 million have been sold. It has been featured on South Park and Saturday Night Live. It is the voice we all hear when we speak to the internet. Alexa has become one of the most ubiquitous devices ever made. In our next session, we're going to hear from the man behind the voice. Please give a warm welcome to the head scientist of Amazon's Alexa, Rohit Prasad.
Rohit Prasad: Thank you, Casey, and thank you for being here. Let's step back in time a bit to 2014 when we were used to as consumers, to connect to services, or look up information, do keyword searches and then get back a bunch of blue links And then click on a link. Smartphones then made it much easier where we had an app for everything. But then this happened. You had an app explosion. You had bunch of apps on your screen on your smartphone, and all the cognitive load was on you. And from there, you had to make all the decisions. Almost exactly five years back on November six, we announced what was then Amazon Echo, or Alexa, which ushered in a voice based ambient computing which would revolutionize daily convenience as we know it. The cognitive load shifted from customers or consumers to the AI where you just spoke and you get an answer back. 
Rohit Prasad: At launch of Alexa, we had to be great at four different AI tasks. The first of them was wake word detection, by which we mean when you say Alexa, it should wake up using on device detection, distinguishing that you are trying to speak and get the device's attention. That technology has gotten four times better. We had our errors go down by a factor of four over the last five years. The second technology is automatic speech recognition, where the goal is that when you speak and the devices woken up and your audio goes into the cloud, you automatically as the AI translate the audio into words. This task is called automatic speech recognition. On this as well, we have made Alexa four times better. Again by using a suite of techniques that will touch upon. The third AI task is now that you have the words ,what do they actually mean? By far the hardest AI task that we know of. Here again, we have made Alexa three times better. At the same time expanding the number of concepts it understands exponentially. The fourth one, the last one in terms of the foundational AI task was when Alexa gets back to you with a response and needs to convert the text into speech, which we call text to speech synthesis. Let's take a look at here on how Alexa sounded in 2014 and how it sounds now in 2019. First 2014
Someone: Star Trek is an American media franchise based on the science fiction TV series created by Gene Roddenberry. 
Someone: Star Trek is an American media franchise based on the science fiction TV series created by Gene Roddenberry.
Rohit Prasad: As you can see much smoother, much more natural.
Rohit Prasad: How did this improvement happen? From the very first days of Alexa in 2014, we were very big on deep learning married with a lot of compute resources that we're available in AWS, and large quantities of data. Since then, we have advanced many of these techniques to use much more sophisticated techniques like active learning, or semi supervised learning, where we can learn with lot of unlabeled data and also transfer learning from one task to another which is called transfer learning. Also, intelligence goes a lot with context. And we have made each component that I talked about be more context aware, and that has translated to all these improvements as well. So how has the adoption been with the customers. Alexa is magical for customers, starting with entertainment where you're trying to get content, easily access, whether it be your music or your video content, any form of content. Customers naturally ask Alexa questions, which are information related, ranging from weather or the news and get back and answer. Alex is also making tasks that we consider very complicated, like shopping much easier. And what has been a huge surprise. And a pleasant one is smart home where we have lot of connected devices that are easy to access and control through Alexa. 
Rohit Prasad: What does this mean? So if you go and look at the number of interactions we used to have in 2014 to 2019 now we have billions of interactions per week through Alexa, all through voice. It's also available in 80 plus countries and 15 Language variants. It is getting more and more ubiquitous and much more natural to interact with Alexa Weil far field speech, recognition and understanding for conversational AI was a big paradigm change, and equal one that's happening and that we introduced in 2015 was the democratization of conversational AI. We specifically introduced to capabilities Alexa voice service that makes it super easy for developers to integrate Alexa into their devices. And Alexa skills kit, which lets you build an experience on Alexa with what is called skills are going to apps on smartphones, but I'll talk about some of the nuances with skills. And these two have had huge adoption with developers. If you look at Alexa voice service, it has enabled hundreds of device types where Alexa is not built in. There are 85,000 compatible devices from 900,500 brands. If you look at Alexa skills kit, we are now at hundred thousand plus skills worldwide, which means there's a skill for any occasion anytime that's delighting our customers and developers around the world are in making this happen.
Rohit Prasad: As we go into the next stage of our evolution, we think of key pillars for better customer experience. And I want to walk through those in the next section of the store. First and foremost is we want our AI to be trusted by our customers. And this has been true from very day one, that our entire tonight is about transparency and control of the data in the hands of the customers. Here we are brought the convenience of voice again, where Alex I can tell you can ask Alexa. Alexa, tell me what you heard. And it will give you a response back about that. So the same convenience of voice computing is now being brought into making sure you have more transparent AI. And more control. And more control is made possible where you can say Alexa, delete what I just said, or delete everything I said today's pretty simple, you just bring the convenience of voice again. The second aspect, while there has been huge advances in deep learning, it is still much more reliant on supervised learning where humans have to label some amount of data. We are inventing lot of different techniques where Alexa gets smarter for our customers with no human in the loop. Let's take an example first, this is semi supervised speech recognition training, which means Alexa improves that speech recognition system automatically using unlabeled data very Powerful teacher model again deep learning base train teachers the student model to get better using a million hours plus of unlabeled data as a no humans are involved in making Alexa smarter from understanding words. The second one, which is another fascinating problem that we have solving and have introduced, where you have let's say you say play abc song and it doesn't work. Alexa from your rephrase if you said Alexa play the alphabet song, semantic learns that semantic equal in that abc song and alphabet song are the same, and directly from customers modifies, and learns that these are semantically equivalent, and it can rewrite a request into a motor into a form that works later. In this case, play the alphabet song and results in the right action from Alexa. The third, Alexa, just like an AI intelligence is tied to a lot of things Knowledge. Over the years we have added billions and billions of facts to Alex's knowledge base, and also innovated such that customers themselves can provide answers for Alexa through it through a capability called Alexa answers. Another pillar is more proactive and context aware. This is where Alexa is going just far beyond words and learning about context in many different form. One search capability is hunches that Alexa has a hunch that you probably left the garage door light on and reminds you to turn it off. Another one is a feature we call Alexa God, where Alexa can practically tell you if you went if you left your home and you said Alexa on God, that it listens for sound events like your glass breaking or carbon dioxide alarm or carbon monoxide alarm or, or your smoke alarm in general going on and then it sends you a notification on your phone. So there you can check on it. Alexa is also getting much and much more natural. Again, a key tenet for human machine interaction. The first form is where you have these hundred thousand skills. How can you make it so easy that Alex Adjust gets you the right skill and takes the right action. So instead of saying, Alexa asked Ruby to clean my room, you can just say Alexa starts cleaning. Or if you have multiple commands you wanted to issue within one sentence, you can do that by saying, turn on the lights and play Adele, for instance. Or Alexa, when do I have to go to mom's house you don't have to worry about did you enter it in a calendar or as a reminder, Alexa naturally fetches you the right action.
Rohit Prasad: We also want the AI to be more fun, and one of the things I'll play here will show you how we are in Getting more celebrity voices on Alexa. And here's an example. Let me play this for you.
Someone: Just like we practiced ready,
Someone: I'm always ready.
Someone: Showtime.
Someone: A day in Los Angeles. It's 85 degrees say my name. Aren't we organized?
Someone: Not bad for a rookie.
Someone: Say rookie again. I dare you. 
Someone: What could be more fun.
Rohit Prasad: Alexa also has been great at completing transactions, but now needs to move into more where it can anticipates customers goal, the next particular move to make in terms of a dialogue problem and let you accomplish what you as a customer are looking for. On that we have introduced a new deep learning based technology that makes it super easy for developers to author these complex skills. Let's say you're trying to build a skill for me Ticket purchases. Instead of you listing all the different ways customers could purchase movie tickets, you just provide a few examples. And Alexa makes it super easy for you. This technology has reduced the amount of code you have to offer as a developer by a factor of three and reduce the data needs by 10 times. Again, machine learning being extremely powerful for our developers. The second part of technology like this is imagine if you wanted to complete a night out interaction with Alexa. Today, you would have to invoke many different skills, one for movie tickets, another to get a ride another to book a table. But what if Alexa could just combine all of this into one seamless interaction? We are making this possible as well for our customers through the same deep learning based technology.
Someone: Hi this is Alexa, how can I help you?
Someone: Delivery for John is someone home?
Someone: Hi, I'm Gina and I'm selling cookies 
Someone: May I know the purpose of your visit, I can take a message 
Someone: Great.
Someone: Does it need a signature 
Someone: Nope. 
Someone: Can you please leave the package on the side of the house, please provide your name and best way to contact you.
Someone: You can get them from our website.
Someone: I will send your message. 
Someone: Okay, thank you.
Rohit Prasad: So that was an example where Alexa can also act on your behalf through again the same technology of Alexa conversations that makes Alexa have a dialogue with someone at your door where it's acting on your behalf. So let's take a look at journey ahead. I think of Alexa being everywhere for our customers available for them anytime. To that end. We have interesting Many new devices that make Alexa more convenient on the go. You now have an echo Bort, an echo glass frames, you have a echo ring which is called the echo loop. That all lets you be have Alexa video so that you can, it can help you at whatever you need on the go. We revolutionized five years back with Alexa in the home, we are very optimistic about Alexa being useful on the go as well. I also want to point out while we have made huge advances in AI, I think of AI is still in its infancy. And we are moving up the AI stack where we were for a while great at what I showed in 2014 about phenomenal modeling. Let's take task like automatic speech recognition variable modeling the speech as a phenomena or now where we are taking a lot of context to make smart decisions for our customers. But Alexa to go to some of the things I showed you in terms of the doorbell concerts where it interacts with person at the door, or Alexa conversations, it has to start reason Moore just like we as humans use a large quantity of context to come with the best outcome in any interaction. The same capability needs to be injected into Alexa. And as we go up in this AI stack, notice I didn't put artificial general intelligence there, but it shows you that we are moving up and up in the stack to make Alexa more useful for our customers. Lastly, it's been to a transformative technology behind Alexa that's making our daily lives useful. But I want Alexa to be available for everyone, everywhere, you and for anyone to invent on where you can expect students to invent as well, or any developer in any corner of the world. I think that Alexa, I'm super optimistic that that will happen. So thank you very much for your time.